#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»»åŠ¡ç®¡ç†æœåŠ¡
"""
from typing import Optional, Dict, List
from datetime import datetime
import uuid
import asyncio
from loguru import logger
import tornado.ioloop

from core.database import get_db
from core.config import settings
from crawler.xhs_client import XHSClient
from .checkpoint_service import CheckpointService
from .account_service import AccountService
from .proxy_service import ProxyService


class TaskService:
    """ä»»åŠ¡ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…äº‹ä»¶å¾ªç¯é—®é¢˜
        self._db = None
        self._collection = None
        self._checkpoint_service = None
        self._account_service = None
        self._proxy_service = None
    
    @property
    def db(self):
        if self._db is None:
            self._db = get_db()
        return self._db
    
    @property
    def collection(self):
        if self._collection is None:
            self._collection = self.db.tasks
        return self._collection
    
    @property
    def checkpoint_service(self):
        if self._checkpoint_service is None:
            self._checkpoint_service = CheckpointService()
        return self._checkpoint_service
    
    @property
    def account_service(self):
        if self._account_service is None:
            self._account_service = AccountService()
        return self._account_service
    
    @property
    def proxy_service(self):
        if self._proxy_service is None:
            self._proxy_service = ProxyService()
        return self._proxy_service
    
    async def create_task(self, task_data: Dict) -> Dict:
        """
        åˆ›å»ºä»»åŠ¡
        
        Args:
            task_data: ä»»åŠ¡æ•°æ®
                {
                    "platform": "xhs",
                    "type": "search",  # search, user, note, homefeed
                    "keywords": ["Python", "ç¼–ç¨‹"],
                    "max_count": 100,
                    "enable_comment": true,
                    "enable_download": false
                }
        
        Returns:
            ä»»åŠ¡ä¿¡æ¯
        """
        try:
            task_id = str(uuid.uuid4())
            
            task = {
                "task_id": task_id,
                **task_data,
                "status": "pending",  # pending, running, completed, failed, cancelled
                "created_at": datetime.now(),
                "updated_at": datetime.now(),
                "started_at": None,
                "completed_at": None,
                "progress": {
                    "total": task_data.get("max_count", 0),
                    "crawled": 0,
                    "success": 0,
                    "failed": 0
                },
                "error": None
            }
            
            await self.collection.insert_one(task)
            
            # è½¬æ¢ ObjectId ä¸ºå­—ç¬¦ä¸²
            task["_id"] = str(task["_id"])
            
            # ä¸è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡ï¼Œé¿å… Event Loop é—®é¢˜
            # ä»»åŠ¡å°†ä¿æŒ pending çŠ¶æ€ï¼Œéœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼å¯åŠ¨
            # TODO: å®ç°ä»»åŠ¡è°ƒåº¦å™¨æˆ–é€šè¿‡å•ç‹¬çš„æ¥å£å¯åŠ¨ä»»åŠ¡
            
            logger.success(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")
            logger.info(f"ğŸ’¡ ä»»åŠ¡å·²åˆ›å»ºï¼ŒçŠ¶æ€ä¸º pendingï¼Œç­‰å¾…æ‰§è¡Œ")
            return task
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_task(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡è¯¦æƒ…"""
        try:
            task = await self.collection.find_one({"task_id": task_id})
            if task:
                task["_id"] = str(task["_id"])
            return task
        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: {e}")
            return None
    
    async def list_tasks(
        self,
        page: int = 1,
        page_size: int = 20,
        status: Optional[str] = None,
        platform: Optional[str] = None
    ) -> Dict:
        """
        è·å–ä»»åŠ¡åˆ—è¡¨
        
        Returns:
            {
                "items": [],
                "total": 100,
                "page": 1,
                "page_size": 20
            }
        """
        try:
            query = {}
            if status:
                query["status"] = status
            if platform:
                query["platform"] = platform
            
            # æ€»æ•°
            total = await self.collection.count_documents(query)
            
            # åˆ†é¡µæŸ¥è¯¢
            skip = (page - 1) * page_size
            cursor = self.collection.find(query).sort("created_at", -1).skip(skip).limit(page_size)
            tasks = await cursor.to_list(length=page_size)
            
            for task in tasks:
                task["_id"] = str(task["_id"])
            
            return {
                "items": tasks,
                "total": total,
                "page": page,
                "page_size": page_size
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return {"items": [], "total": 0, "page": page, "page_size": page_size}
    
    async def start_task(self, task_id: str) -> bool:
        """
        å¯åŠ¨ä»»åŠ¡æ‰§è¡Œ
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        try:
            task = await self.get_task(task_id)
            if not task:
                logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return False
            
            if task["status"] != "pending":
                logger.warning(f"âš ï¸  ä»»åŠ¡çŠ¶æ€ä¸æ˜¯ pendingï¼Œæ— æ³•å¯åŠ¨: {task_id}, å½“å‰çŠ¶æ€: {task['status']}")
                return False
            
            # ä½¿ç”¨ tornado çš„æ–¹å¼å¯åŠ¨åå°ä»»åŠ¡
            tornado.ioloop.IOLoop.current().add_callback(self._execute_task_wrapper, task)
            logger.info(f"ğŸš€ ä»»åŠ¡å·²æäº¤æ‰§è¡Œ: {task_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    async def delete_task(self, task_id: str) -> bool:
        """åˆ é™¤ä»»åŠ¡"""
        try:
            result = await self.collection.delete_one({"task_id": task_id})
            if result.deleted_count > 0:
                # åŒæ—¶åˆ é™¤æ–­ç‚¹
                await self.checkpoint_service.delete_checkpoint(task_id)
                logger.info(f"âœ… åˆ é™¤ä»»åŠ¡æˆåŠŸ: {task_id}")
                return True
            return False
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def _execute_task_wrapper(self, task: Dict):
        """
        ä»»åŠ¡æ‰§è¡ŒåŒ…è£…å™¨ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰
        ç”¨äº Tornado IOLoop.add_callback
        """
        asyncio.ensure_future(self._execute_task(task))
    
    async def _execute_task(self, task: Dict):
        """æ‰§è¡Œä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰"""
        task_id = task["task_id"]
        platform = task["platform"]
        task_type = task["type"]
        
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            await self._update_task_status(task_id, "running", started_at=datetime.now())
            
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")
            
            # æ ¹æ®å¹³å°é€‰æ‹©å®¢æˆ·ç«¯
            if platform == "xhs":
                await self._execute_xhs_task(task)
            elif platform == "douyin":
                # TODO: å®ç°æŠ–éŸ³çˆ¬å–
                pass
            elif platform == "kuaishou":
                # TODO: å®ç°å¿«æ‰‹çˆ¬å–
                pass
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¹³å°: {platform}")
            
            # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            await self._update_task_status(
                task_id,
                "completed",
                completed_at=datetime.now()
            )
            
            logger.success(f"âœ… ä»»åŠ¡å®Œæˆ: {task_id}")
            
        except Exception as e:
            logger.exception(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task_id}")
            await self._update_task_status(
                task_id,
                "failed",
                error=str(e),
                completed_at=datetime.now()
            )
    
    async def _execute_xhs_task(self, task: Dict):
        """æ‰§è¡Œå°çº¢ä¹¦ä»»åŠ¡"""
        task_id = task["task_id"]
        task_type = task["type"]
        max_count = task.get("max_count", 100)
        
        logger.info(f"ğŸ“‹ ä»»åŠ¡è¯¦æƒ…:")
        logger.info(f"   ä»»åŠ¡ID: {task_id}")
        logger.info(f"   ä»»åŠ¡ç±»å‹: {task_type}")
        logger.info(f"   ç›®æ ‡æ•°é‡: {max_count}")
        logger.info(f"   å…³é”®è¯: {task.get('keywords', [])}")
        logger.info(f"   æ˜¯å¦çˆ¬è¯„è®º: {task.get('enable_comment', False)}")
        logger.info(f"   æ˜¯å¦ä¸‹è½½: {task.get('enable_download', False)}")
        
        # è·å–è´¦å·
        logger.info(f"ğŸ” æ­£åœ¨è·å–å¯ç”¨è´¦å·...")
        account = await self.account_service.get_available_account("xhs")
        if not account:
            logger.error(f"âŒ æ²¡æœ‰å¯ç”¨çš„å°çº¢ä¹¦è´¦å·")
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å°çº¢ä¹¦è´¦å·")
        logger.info(f"âœ… ä½¿ç”¨è´¦å·: {account.get('username', account.get('_id'))}")
        
        # è·å–ä»£ç†
        logger.info(f"ğŸ” æ­£åœ¨è·å–ä»£ç†...")
        proxy = await self.proxy_service.get_available_proxy()
        if proxy:
            logger.info(f"âœ… ä½¿ç”¨ä»£ç†: {proxy.get('host')}:{proxy.get('port')}")
        else:
            logger.info(f"ğŸ’¡ ä¸ä½¿ç”¨ä»£ç†ï¼Œç›´è¿")
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        async with XHSClient() as client:
            # è®¾ç½® cookie
            cookie_str = self.account_service.build_cookie_string(account) if account else ""
            if cookie_str:
                client.set_cookie(cookie_str)
            else:
                logger.warning("âš ï¸ æœªè·å–åˆ°è´¦å· Cookieï¼Œå°†ä»¥æœªç™»å½•çŠ¶æ€è®¿é—®")
            
            # è®¾ç½® User-Agentï¼ˆä»è´¦å·é…ç½®è¯»å–ï¼Œä¿è¯ç­¾å UA = è¯·æ±‚ UAï¼‰
            if account and account.get("user_agent"):
                client.set_user_agent(account["user_agent"])
                logger.info(f"âœ… ä½¿ç”¨è´¦å·çœŸå® UA: {account['user_agent'][:50]}...")
            else:
                logger.warning(f"âš ï¸ è´¦å·æœªæä¾› user_agentï¼Œä½¿ç”¨é»˜è®¤ UA")
            
            # è®¾ç½®ä»£ç†
            if proxy:
                client.set_proxy(proxy)
            
            # å°è¯•ä»æ–­ç‚¹æ¢å¤
            checkpoint_data = await self.checkpoint_service.get_checkpoint(task_id)
            start_page = 1
            crawled_count = 0
            
            if checkpoint_data:
                start_page = checkpoint_data.get("current_page", 1)
                crawled_count = checkpoint_data.get("crawled_count", 0)
                logger.info(f"ğŸ”„ ä»æ–­ç‚¹æ¢å¤: ç¬¬ {start_page} é¡µ, å·²çˆ¬å– {crawled_count} æ¡")
            
            # æ ¹æ®ç±»å‹æ‰§è¡Œä¸åŒçš„çˆ¬å–é€»è¾‘
            if task_type == "search":
                await self._execute_xhs_search(
                    client,
                    task,
                    start_page,
                    crawled_count
                )
            elif task_type == "homefeed":
                await self._execute_xhs_homefeed(
                    client,
                    task,
                    checkpoint_data
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}")
    
    async def _execute_xhs_search(
        self,
        client: XHSClient,
        task: Dict,
        start_page: int,
        crawled_count: int
    ):
        """æ‰§è¡Œå°çº¢ä¹¦æœç´¢ä»»åŠ¡"""
        task_id = task["task_id"]
        keywords = task.get("keywords", [])
        max_count = task.get("max_count", 100)
        enable_comment = task.get("enable_comment", False)
        
        for keyword in keywords:
            page = start_page
            keyword_count = 0
            
            while keyword_count < max_count:
                try:
                    # æœç´¢ç¬”è®°
                    notes = await client.search_notes(
                        keyword=keyword,
                        page=page,
                        page_size=20
                    )
                    
                    if not notes:
                        logger.info(f"âš ï¸ å…³é”®è¯ '{keyword}' å·²æ— æ›´å¤šæ•°æ®")
                        break
                    
                    # ä¿å­˜ç¬”è®°
                    for note in notes:
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        await self.db.notes.update_one(
                            {"note_id": note["note_id"]},
                            {"$set": {
                                **note,
                                "source_keyword": keyword,
                                "task_id": task_id,
                                "crawled_at": datetime.now()
                            }},
                            upsert=True
                        )
                        
                        # è·å–è¯„è®º
                        if enable_comment:
                            await self._crawl_comments(client, note["note_id"], task_id)
                        
                        keyword_count += 1
                        crawled_count += 1
                        
                        # æ›´æ–°è¿›åº¦
                        await self._update_task_progress(
                            task_id,
                            total=max_count * len(keywords),
                            crawled=crawled_count
                        )
                        
                        # ä¿å­˜æ–­ç‚¹
                        if await self.checkpoint_service.should_save(crawled_count):
                            await self.checkpoint_service.save_checkpoint(
                                task_id,
                                {
                                    "current_page": page,
                                    "current_keyword": keyword,
                                    "crawled_count": crawled_count,
                                    "keyword_count": keyword_count
                                }
                            )
                        
                        if keyword_count >= max_count:
                            break
                    
                    page += 1
                    
                    # å»¶æ—¶é¿å…å°ç¦
                    await asyncio.sleep(2)
                    
                except Exception as e:
                    logger.error(f"âŒ çˆ¬å–å¤±è´¥: {keyword} ç¬¬{page}é¡µ - {e}")
                    await asyncio.sleep(5)
                    continue
    
    async def _execute_xhs_homefeed(
        self,
        client: XHSClient,
        task: Dict,
        checkpoint_data: Optional[Dict]
    ):
        """æ‰§è¡Œå°çº¢ä¹¦é¦–é¡µæ¨èæµä»»åŠ¡"""
        task_id = task["task_id"]
        max_count = task.get("max_count", 100)
        
        cursor = ""
        if checkpoint_data:
            cursor = checkpoint_data.get("current_cursor", "")
        
        crawled_count = 0
        
        while crawled_count < max_count:
            try:
                result = await client.get_homefeed(cursor=cursor)
                notes = result.get("notes", [])
                cursor = result.get("cursor", "")
                
                if not notes:
                    logger.info("âš ï¸ æ¨èæµå·²æ— æ›´å¤šæ•°æ®")
                    break
                
                for note in notes:
                    await self.db.notes.update_one(
                        {"note_id": note["note_id"]},
                        {"$set": {
                            **note,
                            "source": "homefeed",
                            "task_id": task_id,
                            "crawled_at": datetime.now()
                        }},
                        upsert=True
                    )
                    
                    crawled_count += 1
                    
                    await self._update_task_progress(
                        task_id,
                        total=max_count,
                        crawled=crawled_count
                    )
                    
                    if await self.checkpoint_service.should_save(crawled_count):
                        await self.checkpoint_service.save_checkpoint(
                            task_id,
                            {
                                "current_cursor": cursor,
                                "crawled_count": crawled_count
                            }
                        )
                
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"âŒ çˆ¬å–æ¨èæµå¤±è´¥: {e}")
                await asyncio.sleep(5)
                continue
    
    async def _crawl_comments(self, client: XHSClient, note_id: str, task_id: str):
        """çˆ¬å–è¯„è®ºï¼ˆè‡ªåŠ¨è·å– xsec_tokenï¼‰"""
        try:
            # 1. å°è¯•ä»æ•°æ®åº“è·å–å·²ä¿å­˜çš„ xsec_token
            note = await self.db.notes.find_one({"note_id": note_id})
            xsec_token = note.get("xsec_token", "") if note else ""
            xsec_source = note.get("xsec_source", "pc_search") if note else "pc_search"
            
            # 2. å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ tokenï¼Œåˆ™è°ƒç”¨è¯¦æƒ…æ¥å£è·å–
            if not xsec_token:
                logger.info(f"ğŸ”‘ ç¬”è®° {note_id} ç¼ºå°‘ xsec_tokenï¼Œæ­£åœ¨ä»è¯¦æƒ…é¡µè·å–...")
                detail = await client.get_note_detail_for_token(note_id)
                if detail:
                    xsec_token = detail.get("xsec_token", "")
                    xsec_source = detail.get("xsec_source", "pc_search")
                    
                    # æ›´æ–°æ•°æ®åº“ï¼Œç¼“å­˜ token
                    if xsec_token:
                        await self.db.notes.update_one(
                            {"note_id": note_id},
                            {"$set": {
                                "xsec_token": xsec_token,
                                "xsec_source": xsec_source,
                                "updated_at": datetime.now()
                            }},
                            upsert=True
                        )
                        logger.info(f"âœ… æˆåŠŸè·å–å¹¶ç¼“å­˜ xsec_token: {note_id}")
                else:
                    logger.warning(f"âš ï¸ æ— æ³•è·å–ç¬”è®°è¯¦æƒ…: {note_id}ï¼Œè·³è¿‡è¯„è®ºæŠ“å–")
                    return
            
            # 3. å¦‚æœä»ç„¶æ²¡æœ‰ tokenï¼Œè·³è¿‡è¯„è®ºæŠ“å–
            if not xsec_token:
                logger.warning(f"âš ï¸ ç¬”è®° {note_id} æ— æ³•è·å– xsec_tokenï¼Œè·³è¿‡è¯„è®ºæŠ“å–")
                return
            
            # 4. æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸ºï¼šå»¶è¿Ÿ + Referer é“¾
            # å‚è€ƒè€é¡¹ç›® media_platform/xhs/core.py çš„åšæ³•ï¼šdetail â†’ sleep â†’ comments
            detail_url = f"https://www.xiaohongshu.com/explore/{note_id}?xsec_token={xsec_token}&xsec_source={xsec_source}"
            logger.info(f"ğŸ”— å‡†å¤‡è¯„è®ºæŠ“å–ï¼Œreferer: {detail_url[:60]}...")
            
            # å»¶è¿Ÿï¼Œæ¨¡æ‹Ÿç”¨æˆ·ä»è¯¦æƒ…é¡µé˜…è¯»åˆ°è¯„è®ºåŒºçš„æ—¶é—´
            import asyncio
            sleep_time = settings.COMMENT_REQUEST_INTERVAL if hasattr(settings, 'COMMENT_REQUEST_INTERVAL') else settings.REQUEST_INTERVAL
            logger.debug(f"â° æ¨¡æ‹Ÿç”¨æˆ·é˜…è¯»è¯¦æƒ…é¡µï¼Œç­‰å¾… {sleep_time}s...")
            await asyncio.sleep(sleep_time)
            
            # 5. ä½¿ç”¨ token è·å–è¯„è®ºï¼ˆå¸¦æ­£ç¡®çš„ refererï¼‰
            logger.debug(f"ğŸ’¬ æ­£åœ¨è·å–è¯„è®º: {note_id} (token: {xsec_token[:20]}...)")
            result = await client.get_note_comments(
                note_id=note_id,
                xsec_token=xsec_token,
                xsec_source=xsec_source,
                referer=detail_url  # ä¼ é€’è¯¦æƒ…é¡µä½œä¸º referer
            )
            comments = result.get("comments", [])
            
            # 5. ä¿å­˜è¯„è®ºåˆ°æ•°æ®åº“
            for comment in comments:
                await self.db.comments.update_one(
                    {"comment_id": comment["comment_id"]},
                    {"$set": {
                        **comment,
                        "note_id": note_id,
                        "task_id": task_id,
                        "crawled_at": datetime.now()
                    }},
                    upsert=True
                )
            
            logger.success(f"âœ… æˆåŠŸçˆ¬å–è¯„è®º: {note_id} ({len(comments)} æ¡)")
            
        except Exception as e:
            logger.error(f"âŒ çˆ¬å–è¯„è®ºå¤±è´¥: {note_id} - {e}")
            import traceback
            logger.debug(traceback.format_exc())
    
    async def _update_task_status(
        self,
        task_id: str,
        status: str,
        **kwargs
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        update_data = {
            "status": status,
            "updated_at": datetime.now(),
            **kwargs
        }
        
        await self.collection.update_one(
            {"task_id": task_id},
            {"$set": update_data}
        )
    
    async def _update_task_progress(
        self,
        task_id: str,
        total: int,
        crawled: int
    ):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        await self.collection.update_one(
            {"task_id": task_id},
            {"$set": {
                "progress.total": total,
                "progress.crawled": crawled,
                "updated_at": datetime.now()
            }}
        )



